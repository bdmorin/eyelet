{
  "timestamp": "2025-07-29T16:23:11.050203",
  "timestamp_unix": 1753824191.050203,
  "hook_type": "PostToolUse",
  "tool_name": "Edit",
  "session_id": "54fdad9f-00f2-4c7a-8f11-7da7b149c513",
  "transcript_path": "/Users/bdmorin/.claude/projects/-Users-bdmorin-src-claude-hooks/54fdad9f-00f2-4c7a-8f11-7da7b149c513.jsonl",
  "cwd": "/Users/bdmorin/src/claude-hooks",
  "environment": {
    "python_version": "3.12.10 (main, Apr  9 2025, 03:49:38) [Clang 20.1.0 ]",
    "platform": "darwin",
    "eyelet_version": "0.2.0",
    "env_vars": {
      "CLAUDE_CODE_ENTRYPOINT": "cli",
      "CLAUDE_PROJECT_DIR": "/Users/bdmorin/src/claude-hooks",
      "CLAUDE_CODE_ENABLE_TELEMETRY": "1"
    }
  },
  "input_data": {
    "session_id": "54fdad9f-00f2-4c7a-8f11-7da7b149c513",
    "transcript_path": "/Users/bdmorin/.claude/projects/-Users-bdmorin-src-claude-hooks/54fdad9f-00f2-4c7a-8f11-7da7b149c513.jsonl",
    "cwd": "/Users/bdmorin/src/claude-hooks",
    "hook_event_name": "PostToolUse",
    "tool_name": "Edit",
    "tool_input": {
      "file_path": "/Users/bdmorin/src/claude-hooks/src/eyelet/services/hook_logger.py",
      "old_string": "                except:\n                    pass",
      "new_string": "                except Exception:\n                    pass",
      "replace_all": true
    },
    "tool_response": {
      "filePath": "/Users/bdmorin/src/claude-hooks/src/eyelet/services/hook_logger.py",
      "oldString": "                except:\n                    pass",
      "newString": "                except Exception:\n                    pass",
      "originalFile": "\"\"\"Unified hook logging service supporting JSON files and SQLite.\"\"\"\n\nimport json\nimport os\nimport sys\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any\n\nfrom eyelet.domain.config import LogFormat, LogScope\nfrom eyelet.domain.hooks import HookData\nfrom eyelet.services.config_service import ConfigService\nfrom eyelet.services.git_metadata import GitMetadata\nfrom eyelet.services.sqlite_logger import SQLiteLogger\n\n\nclass HookLogger:\n    \"\"\"Unified logger that handles both JSON file and SQLite logging.\"\"\"\n\n    def __init__(self, config_service: ConfigService, project_dir: Path | None = None):\n        \"\"\"Initialize hook logger.\n        \n        Args:\n            config_service: Configuration service instance\n            project_dir: Project directory for context\n        \"\"\"\n        self.config_service = config_service\n        self.config = config_service.get_config()\n        self._sqlite_loggers: dict[str, SQLiteLogger] = {}\n        self._git_metadata = GitMetadata(project_dir)\n\n    def _get_sqlite_logger(self, path: Path) -> SQLiteLogger:\n        \"\"\"Get or create SQLite logger for path.\"\"\"\n        path_str = str(path)\n        if path_str not in self._sqlite_loggers:\n            db_path = path / \"eyelet.db\"\n            self._sqlite_loggers[path_str] = SQLiteLogger(db_path)\n        return self._sqlite_loggers[path_str]\n\n    def _create_hook_data(self, input_data: dict[str, Any], start_time: datetime) -> HookData:\n        \"\"\"Create HookData object from raw input.\"\"\"\n        # Extract core fields\n        hook_type = input_data.get('hook_event_name', 'unknown')\n        tool_name = input_data.get('tool_name', '')\n        session_id = input_data.get('session_id', 'unknown')\n\n        # Build HookData\n        hook_data = HookData(\n            timestamp=start_time.isoformat(),\n            timestamp_unix=start_time.timestamp(),\n            hook_type=hook_type,\n            tool_name=tool_name,\n            session_id=session_id,\n            transcript_path=input_data.get('transcript_path', ''),\n            cwd=Path(input_data.get('cwd', os.getcwd())),\n            environment={\n                \"python_version\": sys.version,\n                \"platform\": sys.platform,\n                \"eyelet_version\": \"0.2.0\",  # TODO: Import from __version__\n                \"env_vars\": {\n                    k: v for k, v in os.environ.items()\n                    if k.startswith(('CLAUDE', 'EYELET', 'ANTHROPIC'))\n                }\n            },\n            input_data=input_data,\n            metadata={}\n        )\n\n        # Add Git metadata if enabled\n        if self.config.metadata.include_hostname or self.config.metadata.include_ip:\n            # Add system metadata\n            import socket\n            if self.config.metadata.include_hostname:\n                try:\n                    hook_data.metadata['hostname'] = socket.gethostname()\n                except:\n                    pass\n\n            if self.config.metadata.include_ip:\n                try:\n                    hostname = socket.gethostname()\n                    hook_data.metadata['ip_address'] = socket.gethostbyname(hostname)\n                except:\n                    pass\n\n        # Add Git metadata\n        git_info = self._git_metadata.get_metadata()\n        if git_info:\n            hook_data.metadata['git'] = git_info\n\n        # Add custom fields from config\n        if self.config.metadata.custom_fields:\n            hook_data.metadata.update(self.config.metadata.custom_fields)\n\n        return hook_data\n\n    def _log_to_json_file(self, hook_data: HookData, log_dir: Path) -> Path:\n        \"\"\"Log hook data to JSON file.\n        \n        Args:\n            hook_data: Hook data to log\n            log_dir: Directory to log to\n            \n        Returns:\n            Path to created log file\n        \"\"\"\n        # Build directory structure\n        if hook_data.hook_type in ['PreToolUse', 'PostToolUse'] and hook_data.tool_name:\n            dir_path = log_dir / hook_data.hook_type / hook_data.tool_name / datetime.now().strftime(\"%Y-%m-%d\")\n        elif hook_data.hook_type == 'PreCompact':\n            compact_type = hook_data.input_data.get('compact_type', 'unknown')\n            dir_path = log_dir / hook_data.hook_type / compact_type / datetime.now().strftime(\"%Y-%m-%d\")\n        else:\n            dir_path = log_dir / hook_data.hook_type / datetime.now().strftime(\"%Y-%m-%d\")\n\n        # Create directory\n        dir_path.mkdir(parents=True, exist_ok=True)\n\n        # Create filename\n        timestamp_str = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n        if hook_data.tool_name:\n            filename = f\"{timestamp_str}_{hook_data.hook_type}_{hook_data.tool_name}.json\"\n        else:\n            filename = f\"{timestamp_str}_{hook_data.hook_type}.json\"\n\n        log_file = dir_path / filename\n\n        # Add file metadata\n        hook_data.metadata.update({\n            \"log_file\": str(log_file),\n            \"log_dir\": str(dir_path),\n            \"project_dir\": str(hook_data.cwd)\n        })\n\n        # Write log file\n        with open(log_file, 'w') as f:\n            json.dump(hook_data.model_dump(), f, indent=2, default=str)\n\n        return log_file\n\n    def log_hook(self, input_data: dict[str, Any], start_time: datetime | None = None) -> dict[str, Any]:\n        \"\"\"Log hook data according to configuration.\n        \n        Args:\n            input_data: Raw hook input data\n            start_time: Start time (defaults to now)\n            \n        Returns:\n            Dictionary with logging results\n        \"\"\"\n        if not self.config.logging.enabled:\n            return {\"status\": \"disabled\"}\n\n        if start_time is None:\n            start_time = datetime.now()\n\n        # Create hook data\n        hook_data = self._create_hook_data(input_data, start_time)\n\n        # Store for potential updates\n        self._last_hook_data = hook_data\n\n        # Get logging paths\n        paths = self.config_service.get_effective_logging_paths()\n        results = {\"status\": \"success\", \"logs\": []}\n\n        # Determine where to log based on scope\n        log_locations = []\n        if self.config.logging.scope in [LogScope.PROJECT, LogScope.BOTH]:\n            log_locations.append((\"project\", paths['project']))\n        if self.config.logging.scope in [LogScope.GLOBAL, LogScope.BOTH]:\n            log_locations.append((\"global\", paths['global']))\n\n        # Log to each location\n        for location_type, path in log_locations:\n            if self.config.logging.format in [LogFormat.JSON, LogFormat.BOTH]:\n                # JSON file logging\n                json_dir = path if path.name != \"eyelet.db\" else path.parent\n                log_file = self._log_to_json_file(hook_data, json_dir)\n                results[\"logs\"].append({\n                    \"type\": \"json\",\n                    \"location\": location_type,\n                    \"path\": str(log_file)\n                })\n\n            if self.config.logging.format in [LogFormat.SQLITE, LogFormat.BOTH]:\n                # SQLite logging\n                sqlite_logger = self._get_sqlite_logger(path)\n                success = sqlite_logger.log_hook(hook_data)\n                results[\"logs\"].append({\n                    \"type\": \"sqlite\",\n                    \"location\": location_type,\n                    \"path\": str(path / \"eyelet.db\"),\n                    \"success\": success\n                })\n\n        return results\n\n    def update_hook_result(\n        self,\n        hook_data: HookData,\n        status: str,\n        duration_ms: int,\n        output_data: dict[str, Any] | None = None,\n        error_message: str | None = None\n    ) -> None:\n        \"\"\"Update hook with execution results.\n        \n        This is called after hook execution completes to add results.\n        For JSON files, we re-read and update. For SQLite, this would\n        be handled differently in a future implementation.\n        \"\"\"\n        # Update hook data\n        from eyelet.domain.hooks import ExecutionResult\n        hook_data.execution = ExecutionResult(\n            status=status,\n            duration_ms=duration_ms,\n            output_data=output_data or {},\n            error_message=error_message\n        )\n        hook_data.completed_at = datetime.now().isoformat()\n\n        # If we logged to JSON files, update them\n        if \"log_file\" in hook_data.metadata:\n            try:\n                log_file = Path(hook_data.metadata[\"log_file\"])\n                if log_file.exists():\n                    with open(log_file, 'w') as f:\n                        json.dump(hook_data.model_dump(), f, indent=2, default=str)\n            except Exception:\n                pass  # Don't fail on update errors\n",
      "structuredPatch": [
        {
          "oldStart": 73,
          "oldLines": 14,
          "newStart": 73,
          "newLines": 14,
          "lines": [
            "             if self.config.metadata.include_hostname:",
            "                 try:",
            "                     hook_data.metadata['hostname'] = socket.gethostname()",
            "-                except:",
            "+                except Exception:",
            "                     pass",
            " ",
            "             if self.config.metadata.include_ip:",
            "                 try:",
            "                     hostname = socket.gethostname()",
            "                     hook_data.metadata['ip_address'] = socket.gethostbyname(hostname)",
            "-                except:",
            "+                except Exception:",
            "                     pass",
            " ",
            "         # Add Git metadata"
          ]
        }
      ],
      "userModified": false,
      "replaceAll": true
    }
  },
  "metadata": {
    "log_file": "/Users/bdmorin/src/claude-hooks/eyelet-hooks/PostToolUse/Edit/2025-07-29/20250729_162311_050203_PostToolUse_Edit.json",
    "log_dir": "/Users/bdmorin/src/claude-hooks/eyelet-hooks/PostToolUse/Edit/2025-07-29",
    "project_dir": "/Users/bdmorin/src/claude-hooks"
  },
  "execution": {
    "status": "success",
    "duration_ms": 4,
    "output_data": {
      "action": "logged"
    },
    "error_message": null
  },
  "completed_at": "2025-07-29T16:23:11.054682"
}